# 9ï¸âƒ£ å¼·åŒ–å­¸ç¿’

## ğŸ¯ ä»€éº¼æ˜¯å¼·åŒ–å­¸ç¿’ï¼Ÿ

å¼·åŒ–å­¸ç¿’ï¼ˆReinforcement Learning, RLï¼‰æ˜¯ä¸€ç¨® **åŸºæ–¼çå‹µèˆ‡æ‡²ç½°çš„å­¸ç¿’æ–¹æ³•**ï¼Œå¸¸ç”¨æ–¼ **éŠæˆ² AIã€æ©Ÿå™¨äººæ§åˆ¶ã€è‡ªå‹•é§•é§›** ç­‰é ˜åŸŸã€‚

âœ… **å¼·åŒ–å­¸ç¿’çš„æ ¸å¿ƒæ¦‚å¿µ**ï¼š

1. **ä»£ç†ï¼ˆAgentï¼‰**ï¼šå­¸ç¿’è€…ï¼Œå¦‚æ©Ÿå™¨äººæˆ– AI æ¨¡å‹ã€‚
2. **ç’°å¢ƒï¼ˆEnvironmentï¼‰**ï¼šä»£ç†èˆ‡ä¹‹äº’å‹•çš„ä¸–ç•Œã€‚
3. **å‹•ä½œï¼ˆActionï¼‰**ï¼šä»£ç†å¯ä»¥æ¡å–çš„è¡Œç‚ºã€‚
4. **ç‹€æ…‹ï¼ˆStateï¼‰**ï¼šç’°å¢ƒåœ¨æŸå€‹æ™‚é–“é»çš„æƒ…æ³ã€‚
5. **çå‹µï¼ˆRewardï¼‰**ï¼šä»£ç†æ ¹æ“šå‹•ä½œç²å¾—çš„å›é¥‹ã€‚

---

## **âœ… å»ºç«‹ Q-learning æ¨¡å‹**

Q-learning æ˜¯ä¸€ç¨®åŸºæœ¬çš„å¼·åŒ–å­¸ç¿’ç®—æ³•ï¼Œæˆ‘å€‘å¯ä»¥ä½¿ç”¨ Keras ä¾†å»ºç«‹ Q-learning ç¥ç¶“ç¶²è·¯ã€‚

```python
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# å»ºç«‹ Q-learning æ¨¡å‹
model = keras.Sequential([
    layers.Dense(24, activation='relu', input_shape=(4,)),
    layers.Dense(24, activation='relu'),
    layers.Dense(2, activation='linear')
])

# ç·¨è­¯æ¨¡å‹
model.compile(optimizer='adam', loss='mse')
```

âœ… **é€™æ˜¯ä¸€å€‹ç”¨æ–¼ OpenAI Gym CartPole çš„åŸºæœ¬ Q-learning æ¨¡å‹ã€‚**

---

## **âœ… è¨“ç·´ Q-learning æ¨¡å‹**

åœ¨å¼·åŒ–å­¸ç¿’ä¸­ï¼Œæˆ‘å€‘éœ€è¦é€éåè¦†è©¦éŒ¯ä¾†å­¸ç¿’æœ€å„ªç­–ç•¥ã€‚

```python
import gym

# åˆå§‹åŒ–ç’°å¢ƒ
env = gym.make("CartPole-v1")

# è¨­å®šåƒæ•¸
num_episodes = 1000
for episode in range(num_episodes):
    state = env.reset()
    state = np.reshape(state, [1, 4])
    done = False
    while not done:
        action = np.argmax(model.predict(state)[0])
        next_state, reward, done, _ = env.step(action)
        next_state = np.reshape(next_state, [1, 4])
        state = next_state
```

âœ… **é€™æ®µç¨‹å¼ç¢¼æœƒè®“ AI å˜—è©¦å­¸ç¿’å¦‚ä½•åœ¨ CartPole ç’°å¢ƒä¸­å–å¾—è¼ƒé«˜çš„åˆ†æ•¸ã€‚**

---

## ğŸ“ **ç¸½çµ**

| **æ¦‚å¿µ** | **èªªæ˜** |
|----------|--------|
| **ä»£ç†ï¼ˆAgentï¼‰** | å­¸ç¿’èˆ‡æ±ºç­–çš„ AI æ¨¡å‹ |
| **ç’°å¢ƒï¼ˆEnvironmentï¼‰** | AI èˆ‡ä¹‹äº’å‹•çš„ä¸–ç•Œï¼Œå¦‚éŠæˆ²ã€ç‰©ç†å ´æ™¯ |
| **å‹•ä½œï¼ˆActionï¼‰** | ä»£ç†å¯ä»¥åŸ·è¡Œçš„è¡Œç‚º |
| **çå‹µï¼ˆRewardï¼‰** | ä»£ç†æ ¹æ“šå‹•ä½œç²å¾—çš„å›é¥‹ |

ğŸš€ **ç¾åœ¨ä½ å·²ç¶“å­¸æœƒå¦‚ä½•ä½¿ç”¨ Keras ä¾†å¯¦ä½œå¼·åŒ–å­¸ç¿’ï¼æ¥ä¸‹ä¾†ï¼Œæˆ‘å€‘å°‡å­¸ç¿’ Keras åœ¨é€²éšæ‡‰ç”¨èˆ‡å°ˆæ¡ˆç¤ºç¯„ä¸­çš„æ‡‰ç”¨ï¼** ğŸ˜Š

