# 4ï¸âƒ£ æ¨¡å‹è¨“ç·´èˆ‡è©•ä¼°

## ğŸ¯ è¨“ç·´ç¥ç¶“ç¶²è·¯çš„åŸºæœ¬æ¦‚å¿µ

åœ¨å»ºç«‹ Keras æ¨¡å‹å¾Œï¼Œæˆ‘å€‘éœ€è¦é€é **è¨“ç·´ï¼ˆTrainingï¼‰** ä¾†èª¿æ•´æ¬Šé‡ï¼Œä½¿æ¨¡å‹èƒ½å¤ å°æ‡‰è¼¸å…¥æ•¸æ“šé€²è¡Œæ­£ç¢ºçš„é æ¸¬ã€‚

âœ… **è¨“ç·´æµç¨‹**ï¼š

1. **å®šç¾©æå¤±å‡½æ•¸ï¼ˆLoss Functionï¼‰**
2. **é¸æ“‡å„ªåŒ–å™¨ï¼ˆOptimizerï¼‰**
3. **è¨­å®šè©•ä¼°æŒ‡æ¨™ï¼ˆMetricsï¼‰**
4. **åŸ·è¡Œè¨“ç·´ï¼ˆFit Modelï¼‰**
5. **æ¨¡å‹è©•ä¼°ï¼ˆEvaluate Modelï¼‰**

---

## **âœ… ç·¨è­¯æ¨¡å‹ï¼ˆCompile Modelï¼‰**

Keras éœ€è¦åœ¨è¨“ç·´å‰ **ç·¨è­¯ï¼ˆcompileï¼‰** æ¨¡å‹ï¼Œè¨­å®šæå¤±å‡½æ•¸èˆ‡å„ªåŒ–å™¨ã€‚

```python
from tensorflow import keras
from tensorflow.keras import layers

# å»ºç«‹æ¨¡å‹
model = keras.Sequential([
    layers.Dense(128, activation='relu', input_shape=(10,)),
    layers.Dense(64, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])

# ç·¨è­¯æ¨¡å‹
model.compile(
    optimizer='adam', 
    loss='binary_crossentropy', 
    metrics=['accuracy']
)
```

âœ… **`adam` æ˜¯ä¸€ç¨®å¸¸ç”¨çš„å„ªåŒ–å™¨ï¼Œé©åˆå¤§å¤šæ•¸æ·±åº¦å­¸ç¿’æ‡‰ç”¨ã€‚**

---

## **âœ… è¨“ç·´æ¨¡å‹ï¼ˆModel Trainingï¼‰**

æˆ‘å€‘å¯ä»¥ä½¿ç”¨ `fit()` æ–¹æ³•ä¾†è¨“ç·´æ¨¡å‹ã€‚

```python
import numpy as np

# å»ºç«‹å‡è¨­æ•¸æ“š
x_train = np.random.rand(100, 10)
y_train = np.random.randint(0, 2, size=(100,))

# è¨“ç·´æ¨¡å‹
model.fit(x_train, y_train, epochs=10, batch_size=32)
```

âœ… **`epochs=10` è¡¨ç¤ºè¨“ç·´ 10 æ¬¡å®Œæ•´æ•¸æ“šé›†ï¼Œ`batch_size=32` è¡¨ç¤ºæ¯æ¬¡æ›´æ–° 32 å€‹æ¨£æœ¬ã€‚**

---

## **âœ… æ¨¡å‹è©•ä¼°ï¼ˆEvaluate Modelï¼‰**

è¨“ç·´å®Œæˆå¾Œï¼Œæˆ‘å€‘å¯ä»¥ä½¿ç”¨æ¸¬è©¦æ•¸æ“šä¾†è©•ä¼°æ¨¡å‹çš„è¡¨ç¾ã€‚

```python
x_test = np.random.rand(20, 10)
y_test = np.random.randint(0, 2, size=(20,))

# è©•ä¼°æ¨¡å‹
loss, acc = model.evaluate(x_test, y_test)
print(f"æ¸¬è©¦æº–ç¢ºç‡ï¼š{acc:.2f}")
```

âœ… **é€™å°‡è¿”å›æ¨¡å‹çš„æå¤±èˆ‡æº–ç¢ºç‡ï¼Œç”¨ä¾†è¡¡é‡æ¨¡å‹çš„æ•ˆèƒ½ã€‚**

---

## **âœ… ä½¿ç”¨ `validation_data` é€²è¡Œé©—è­‰**

æˆ‘å€‘å¯ä»¥åœ¨è¨“ç·´éç¨‹ä¸­ä½¿ç”¨ `validation_data` ä¾†è§€å¯Ÿæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

```python
model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))
```

âœ… **é€™æ¨£å¯ä»¥çœ‹åˆ°è¨“ç·´æ•¸æ“šèˆ‡é©—è­‰æ•¸æ“šçš„æº–ç¢ºç‡ï¼Œé¿å…éæ“¬åˆã€‚**

---

## **âœ… ä½¿ç”¨ Early Stopping é˜²æ­¢éæ“¬åˆ**

ç•¶è¨“ç·´éç¨‹ä¸­ç™¼ç¾ **é©—è­‰é›†æº–ç¢ºç‡ä¸å†æå‡**ï¼Œå¯ä»¥é€é `EarlyStopping` ä¾†åœæ­¢è¨“ç·´ã€‚

```python
from tensorflow.keras.callbacks import EarlyStopping

# è¨­å®š EarlyStopping
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# è¨“ç·´æ¨¡å‹
model.fit(x_train, y_train, epochs=50, batch_size=32, validation_data=(x_test, y_test), callbacks=[early_stopping])
```
âœ… **é€™æ¨£å¯ä»¥é˜²æ­¢æ¨¡å‹éæ“¬åˆï¼Œç•¶ `val_loss` é€£çºŒ 3 å€‹ epochs æ²’æœ‰æ”¹å–„æ™‚åœæ­¢è¨“ç·´ã€‚**

---

## ğŸ“ **ç¸½çµ**

| **åŠŸèƒ½** | **èªæ³•** |
|----------|--------|
| **ç·¨è­¯æ¨¡å‹** | `model.compile(optimizer, loss, metrics)` |
| **è¨“ç·´æ¨¡å‹** | `model.fit(x_train, y_train, epochs, batch_size)` |
| **è©•ä¼°æ¨¡å‹** | `model.evaluate(x_test, y_test)` |
| **ä½¿ç”¨é©—è­‰æ•¸æ“š** | `model.fit(x_train, y_train, validation_data=(x_test, y_test))` |
| **Early Stopping** | `EarlyStopping(monitor='val_loss', patience=3)` |

ğŸš€ **ç¾åœ¨ä½ å·²ç¶“å­¸æœƒå¦‚ä½•è¨“ç·´èˆ‡è©•ä¼° Keras æ¨¡å‹ï¼æ¥ä¸‹ä¾†ï¼Œæˆ‘å€‘å°‡å­¸ç¿’ Keras å¦‚ä½•è™•ç†æ•¸æ“šï¼** ğŸ˜Š

